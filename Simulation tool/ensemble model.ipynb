{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f528c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0878aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Bloodtype</th>\n",
       "      <th>Inpt_attx</th>\n",
       "      <th>Donor_Sex</th>\n",
       "      <th>Donor_Bloodtype</th>\n",
       "      <th>Donor_DCD</th>\n",
       "      <th>Waittime</th>\n",
       "      <th>Age_Tx</th>\n",
       "      <th>Donor_Age</th>\n",
       "      <th>TransplantBMI</th>\n",
       "      <th>Donor_BMI</th>\n",
       "      <th>MELD</th>\n",
       "      <th>MELDNA</th>\n",
       "      <th>Time</th>\n",
       "      <th>Cens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Female</td>\n",
       "      <td>A</td>\n",
       "      <td>home</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>33.446369</td>\n",
       "      <td>40.122933</td>\n",
       "      <td>21.467095</td>\n",
       "      <td>27.574890</td>\n",
       "      <td>6.818314</td>\n",
       "      <td>6.818340</td>\n",
       "      <td>711.869557</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3354</th>\n",
       "      <td>Male</td>\n",
       "      <td>O</td>\n",
       "      <td>home</td>\n",
       "      <td>Female</td>\n",
       "      <td>O</td>\n",
       "      <td>No</td>\n",
       "      <td>17</td>\n",
       "      <td>63.519717</td>\n",
       "      <td>30.716671</td>\n",
       "      <td>26.825953</td>\n",
       "      <td>24.558792</td>\n",
       "      <td>14.353784</td>\n",
       "      <td>16.319223</td>\n",
       "      <td>1890.014093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>home</td>\n",
       "      <td>Female</td>\n",
       "      <td>A</td>\n",
       "      <td>No</td>\n",
       "      <td>11</td>\n",
       "      <td>56.220194</td>\n",
       "      <td>35.848897</td>\n",
       "      <td>30.021367</td>\n",
       "      <td>20.200510</td>\n",
       "      <td>23.248548</td>\n",
       "      <td>29.601779</td>\n",
       "      <td>234.421218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Female</td>\n",
       "      <td>A</td>\n",
       "      <td>home</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>No</td>\n",
       "      <td>7</td>\n",
       "      <td>50.450186</td>\n",
       "      <td>43.000612</td>\n",
       "      <td>29.985210</td>\n",
       "      <td>27.620236</td>\n",
       "      <td>19.538331</td>\n",
       "      <td>18.955805</td>\n",
       "      <td>1765.721400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>Female</td>\n",
       "      <td>A</td>\n",
       "      <td>inpt</td>\n",
       "      <td>Male</td>\n",
       "      <td>O</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>52.389800</td>\n",
       "      <td>63.141957</td>\n",
       "      <td>26.204500</td>\n",
       "      <td>26.333873</td>\n",
       "      <td>34.048790</td>\n",
       "      <td>34.239219</td>\n",
       "      <td>149.456562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>home</td>\n",
       "      <td>Female</td>\n",
       "      <td>A</td>\n",
       "      <td>No</td>\n",
       "      <td>26</td>\n",
       "      <td>56.874962</td>\n",
       "      <td>40.826542</td>\n",
       "      <td>39.737910</td>\n",
       "      <td>27.692980</td>\n",
       "      <td>28.273415</td>\n",
       "      <td>28.280934</td>\n",
       "      <td>1802.611114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960</th>\n",
       "      <td>Male</td>\n",
       "      <td>O</td>\n",
       "      <td>home</td>\n",
       "      <td>Male</td>\n",
       "      <td>O</td>\n",
       "      <td>No</td>\n",
       "      <td>104</td>\n",
       "      <td>50.528682</td>\n",
       "      <td>76.411005</td>\n",
       "      <td>23.962351</td>\n",
       "      <td>29.166056</td>\n",
       "      <td>7.034904</td>\n",
       "      <td>7.032702</td>\n",
       "      <td>829.390460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>home</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>No</td>\n",
       "      <td>71</td>\n",
       "      <td>60.894054</td>\n",
       "      <td>31.876350</td>\n",
       "      <td>21.587780</td>\n",
       "      <td>31.182141</td>\n",
       "      <td>19.727861</td>\n",
       "      <td>16.722346</td>\n",
       "      <td>5947.080294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>home</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>No</td>\n",
       "      <td>60</td>\n",
       "      <td>42.132283</td>\n",
       "      <td>40.799471</td>\n",
       "      <td>39.468128</td>\n",
       "      <td>34.895577</td>\n",
       "      <td>13.171881</td>\n",
       "      <td>15.786446</td>\n",
       "      <td>3389.700446</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>Male</td>\n",
       "      <td>B</td>\n",
       "      <td>home</td>\n",
       "      <td>Male</td>\n",
       "      <td>O</td>\n",
       "      <td>No</td>\n",
       "      <td>133</td>\n",
       "      <td>58.641155</td>\n",
       "      <td>63.075955</td>\n",
       "      <td>15.660507</td>\n",
       "      <td>18.172563</td>\n",
       "      <td>12.706129</td>\n",
       "      <td>10.005637</td>\n",
       "      <td>1423.985784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender Bloodtype Inpt_attx Donor_Sex Donor_Bloodtype Donor_DCD  \\\n",
       "252   Female         A      home      Male               A        No   \n",
       "3354    Male         O      home    Female               O        No   \n",
       "438     Male         A      home    Female               A        No   \n",
       "802   Female         A      home      Male               A        No   \n",
       "1404  Female         A      inpt      Male               O        No   \n",
       "...      ...       ...       ...       ...             ...       ...   \n",
       "244     Male         A      home    Female               A        No   \n",
       "3960    Male         O      home      Male               O        No   \n",
       "168     Male         A      home      Male               A        No   \n",
       "888   Female         B      home    Female               B        No   \n",
       "2941    Male         B      home      Male               O        No   \n",
       "\n",
       "      Waittime     Age_Tx  Donor_Age  TransplantBMI  Donor_BMI       MELD  \\\n",
       "252         34  33.446369  40.122933      21.467095  27.574890   6.818314   \n",
       "3354        17  63.519717  30.716671      26.825953  24.558792  14.353784   \n",
       "438         11  56.220194  35.848897      30.021367  20.200510  23.248548   \n",
       "802          7  50.450186  43.000612      29.985210  27.620236  19.538331   \n",
       "1404         0  52.389800  63.141957      26.204500  26.333873  34.048790   \n",
       "...        ...        ...        ...            ...        ...        ...   \n",
       "244         26  56.874962  40.826542      39.737910  27.692980  28.273415   \n",
       "3960       104  50.528682  76.411005      23.962351  29.166056   7.034904   \n",
       "168         71  60.894054  31.876350      21.587780  31.182141  19.727861   \n",
       "888         60  42.132283  40.799471      39.468128  34.895577  13.171881   \n",
       "2941       133  58.641155  63.075955      15.660507  18.172563  12.706129   \n",
       "\n",
       "         MELDNA         Time  Cens  \n",
       "252    6.818340   711.869557     1  \n",
       "3354  16.319223  1890.014093     1  \n",
       "438   29.601779   234.421218     1  \n",
       "802   18.955805  1765.721400     1  \n",
       "1404  34.239219   149.456562     0  \n",
       "...         ...          ...   ...  \n",
       "244   28.280934  1802.611114     1  \n",
       "3960   7.032702   829.390460     1  \n",
       "168   16.722346  5947.080294     1  \n",
       "888   15.786446  3389.700446     1  \n",
       "2941  10.005637  1423.985784     0  \n",
       "\n",
       "[20000 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_df = pd.read_excel(\"SimData_Transplant_Ver1.0.xls\")\n",
    "tp_df = resample(tp_df, n_samples=20000, replace=1)\n",
    "tp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7477ff67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer(norm = 'l2')\n",
    "train_df = deepcopy(tp_df)\n",
    "train_df.loc[train_df['Time'] < 1825, 'Time'] = 0\n",
    "train_df.loc[train_df['Time'] > 1825, 'Time'] = 1\n",
    "od_array = np.array(train_df['Time'])\n",
    "od_array = od_array.reshape(-1,1)\n",
    "labels = train_df['Time']\n",
    "train_df[['MELD','MELDNA', 'TransplantBMI']] = scaler.fit_transform(train_df[['MELD','MELDNA', 'TransplantBMI']])\n",
    "train_df[['MELD','MELDNA', 'TransplantBMI']] = scaler.fit_transform(train_df[['MELD','MELDNA', 'TransplantBMI']])\n",
    "train_df = train_df[['MELD','MELDNA', 'TransplantBMI']]\n",
    "# define the model\n",
    "#model.fit(train_df)\n",
    "#yhat = model.predict(train_df)\n",
    "# retrieve unique clusters\n",
    "# create scatter plot for samples from each cluster\n",
    "\n",
    "\n",
    "model = AgglomerativeClustering(n_clusters=4)\n",
    "X = train_df\n",
    "X = pd.get_dummies(X)\n",
    "Y = labels\n",
    "X = X.to_numpy()\n",
    "model.fit(X)\n",
    "yhat = model.fit_predict(X)\n",
    "# retrieve unique clusters\n",
    "clusters = unique(yhat)\n",
    "# create scatter plot for samples from each cluster\n",
    "count = 0\n",
    "for cluster in clusters:\n",
    "    # get row indexes for samples with this cluster\n",
    "    count+=1\n",
    "    row_ix = where(yhat == cluster)\n",
    "    #print(\"Cluster: \",count, \"Indexes\", row_ix[0])\n",
    "    # create scatter of these samples\n",
    "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "# show the plot\n",
    "#print(\"Total Cluster\")\n",
    "pyplot.show()\n",
    "\n",
    "tp_df['cluster'] = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4caef25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79937179 0.41632143 0.27881735 ... 0.         0.         0.01612206]\n",
      " [0.77937663 0.35975616 0.32086767 ... 0.         0.01534584 0.        ]\n",
      " [0.53928543 0.50182184 0.45280849 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.86517803 0.32156194 0.2707587  ... 0.         0.01436722 0.        ]\n",
      " [0.79856025 0.35594904 0.29740671 ... 0.         0.         0.        ]\n",
      " [0.83696091 0.39180518 0.2689555  ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_df[['MELD','MELDNA', 'TransplantBMI', 'Time', 'Age_Tx', 'Waittime']] = tp_df[['MELD','MELDNA', 'TransplantBMI', 'Time', 'Age_Tx', 'Waittime']]\\ntrain_df['cluster'] = yhat\\ntrain_df.loc[train_df['Time'] < 1825, 'Time'] = 0\\ntrain_df.loc[train_df['Time'] > 1825, 'Time'] = 1\\nod_array = np.array(train_df['Time'])\\nod_array = od_array.reshape(-1,1)\\nlabels = train_df['Time']\\ntrain_df = train_df[['MELD','MELDNA', 'TransplantBMI', 'Age_Tx', 'Waittime']]\\n\\n\\nfrom sklearn.model_selection import train_test_split\\nX_train,X_test,y_train,y_test = train_test_split(train_df, labels, train_size=0.8,random_state= 42)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = deepcopy(tp_df)\n",
    "train_df = train_df[train_df['cluster'] == 1]\n",
    "num_df = pd.get_dummies(train_df)\n",
    "num_df = num_df.drop(['Waittime','Donor_Age','Donor_BMI','Cens', 'Donor_Sex_Female',\\\n",
    "                  'Donor_Sex_Male','Donor_Bloodtype_A', 'Donor_Bloodtype_B', 'Donor_Bloodtype_O',\\\n",
    "                  'Donor_Bloodtype_AB', 'Donor_DCD_No', 'Donor_DCD_Yes'], axis=1)\n",
    "\n",
    "\n",
    "train_data = num_df\n",
    "train_df = pd.DataFrame(train_data, columns=['Age_Tx', 'TransplantBMI', 'MELD', 'MELDNA', 'Time',  'Gender_Female', 'Gender_Male', 'Bloodtype_A', 'Bloodtype_AB', 'Bloodtype_B', 'Bloodtype_O',\n",
    "                                            'Inpt_attx_home','Inpt_attx_icu','Inpt_attx_inpt','Inpt_attx_ventilated'])\n",
    "\n",
    "\n",
    "train_df.loc[train_df['Time'] < 1825, 'Time'] = 0\n",
    "train_df.loc[train_df['Time'] > 1825, 'Time'] = 1\n",
    "od_array = np.array(train_df['Time'])\n",
    "od_array = od_array.reshape(-1,1)\n",
    "labels = train_df['Time']\n",
    "\n",
    "train_df = train_df[['Age_Tx', 'TransplantBMI', 'MELD', 'MELDNA',  'Gender_Female', 'Gender_Male', 'Bloodtype_A', 'Bloodtype_AB', 'Bloodtype_B', 'Bloodtype_O',\n",
    "                                            'Inpt_attx_home','Inpt_attx_icu','Inpt_attx_inpt','Inpt_attx_ventilated']]\n",
    "scaler = Normalizer(norm = 'l2')\n",
    "train_df= scaler.fit_transform(train_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(train_df, labels, train_size=0.8,random_state= 42)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "#print(X_train)\n",
    "print(X_test)\n",
    "\n",
    "\n",
    "'''\n",
    "train_df[['MELD','MELDNA', 'TransplantBMI', 'Time', 'Age_Tx', 'Waittime']] = tp_df[['MELD','MELDNA', 'TransplantBMI', 'Time', 'Age_Tx', 'Waittime']]\n",
    "train_df['cluster'] = yhat\n",
    "train_df.loc[train_df['Time'] < 1825, 'Time'] = 0\n",
    "train_df.loc[train_df['Time'] > 1825, 'Time'] = 1\n",
    "od_array = np.array(train_df['Time'])\n",
    "od_array = od_array.reshape(-1,1)\n",
    "labels = train_df['Time']\n",
    "train_df = train_df[['MELD','MELDNA', 'TransplantBMI', 'Age_Tx', 'Waittime']]\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(train_df, labels, train_size=0.8,random_state= 42)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4069e9b",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1dc42ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d6455ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 0.01, 10], 'gamma': [10, 0.1, 0.01], 'kernel': ['rbf', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "859f5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "#grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09d54d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bea5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(C=10, gamma=10)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce8d35c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.72      0.64       797\n",
      "         1.0       0.54      0.38      0.45       697\n",
      "\n",
      "    accuracy                           0.56      1494\n",
      "   macro avg       0.56      0.55      0.54      1494\n",
      "weighted avg       0.56      0.56      0.55      1494\n",
      "\n",
      "Accuracy of our mode when applied on test set:  0.5622489959839357\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "\n",
    "print('Classification Report \\n',classification_report(y_test, y_pred))\n",
    "print('Accuracy of our mode when applied on test set: ',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea68bb5",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "605d735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a87b1618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 16:44:36.739168: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Initialising the model\n",
    "model=Sequential()\n",
    "#adding the first layer and input layer\n",
    "model.add(keras.Input(shape=(14,)))\n",
    "model.add(Dense(units=128,kernel_initializer='random_normal',activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "#adding the second layer\n",
    "model.add(Dense(units=128,kernel_initializer='random_normal',activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "#adding the output layer\n",
    "model.add(Dense(units=1,kernel_initializer='random_normal',activation='sigmoid'))\n",
    "model.add(Dropout(.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce6882a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling all the layer together\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50bc022e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "632/632 [==============================] - 5s 6ms/step - loss: 2.1159 - accuracy: 0.5006\n",
      "Epoch 2/20\n",
      "632/632 [==============================] - 4s 6ms/step - loss: 2.1667 - accuracy: 0.5127\n",
      "Epoch 3/20\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 2.0179 - accuracy: 0.5181\n",
      "Epoch 4/20\n",
      "632/632 [==============================] - 2s 3ms/step - loss: 2.0620 - accuracy: 0.5252\n",
      "Epoch 5/20\n",
      "632/632 [==============================] - 2s 3ms/step - loss: 2.0566 - accuracy: 0.5285\n",
      "Epoch 6/20\n",
      "632/632 [==============================] - 2s 3ms/step - loss: 2.0110 - accuracy: 0.5350\n",
      "Epoch 7/20\n",
      "632/632 [==============================] - 4s 7ms/step - loss: 2.1647 - accuracy: 0.5274\n",
      "Epoch 8/20\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 2.1014 - accuracy: 0.5333\n",
      "Epoch 9/20\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 2.1055 - accuracy: 0.5323\n",
      "Epoch 10/20\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 2.0615 - accuracy: 0.5322\n",
      "Epoch 11/20\n",
      "632/632 [==============================] - 4s 7ms/step - loss: 2.0942 - accuracy: 0.5385\n",
      "Epoch 12/20\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 2.0188 - accuracy: 0.5350\n",
      "Epoch 13/20\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 2.1039 - accuracy: 0.5363\n",
      "Epoch 14/20\n",
      "632/632 [==============================] - 2s 3ms/step - loss: 2.1252 - accuracy: 0.5304\n",
      "Epoch 15/20\n",
      "632/632 [==============================] - 2s 4ms/step - loss: 2.1100 - accuracy: 0.5353\n",
      "Epoch 16/20\n",
      "632/632 [==============================] - 2s 3ms/step - loss: 2.1390 - accuracy: 0.5293\n",
      "Epoch 17/20\n",
      "632/632 [==============================] - 2s 4ms/step - loss: 2.1295 - accuracy: 0.5336\n",
      "Epoch 18/20\n",
      "632/632 [==============================] - 2s 3ms/step - loss: 2.2074 - accuracy: 0.5325\n",
      "Epoch 19/20\n",
      "632/632 [==============================] - 2s 3ms/step - loss: 2.0385 - accuracy: 0.5360\n",
      "Epoch 20/20\n",
      "632/632 [==============================] - 2s 3ms/step - loss: 2.0580 - accuracy: 0.5372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faec00f7670>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the data\n",
    "model.fit(X_train,y_train,batch_size=10,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c4e4674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 2ms/step\n",
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.95      0.70       797\n",
      "         1.0       0.70      0.14      0.24       697\n",
      "\n",
      "    accuracy                           0.57      1494\n",
      "   macro avg       0.63      0.54      0.47      1494\n",
      "weighted avg       0.62      0.57      0.48      1494\n",
      "\n",
      "Accuracy of our mode when applied on test set:  0.57095046854083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "predictions=model.predict(X_test)\n",
    "#converting the probablitiy obtained using the predict method to the binary output \n",
    "predictions=(predictions>0.5)\n",
    "print('Classification Report \\n',classification_report(y_test,predictions))\n",
    "print('Accuracy of our mode when applied on test set: ',accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcf6cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69ea07ee",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "156acc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "[CV] END ..............C=0.1, penalty=none, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ..............C=0.1, penalty=none, solver=newton-cg; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.1, penalty=none, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ..............C=0.1, penalty=none, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ..............C=0.1, penalty=none, solver=newton-cg; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.1, penalty=none, solver=lbfgs; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.1, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..................C=0.1, penalty=none, solver=lbfgs; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.1, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..................C=0.1, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..............C=0.1, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............C=0.1, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............C=0.1, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............C=0.1, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............C=0.1, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ............C=0.1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=0.1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=0.1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=0.1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=0.1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=none, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=none, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=1, penalty=none, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=1, penalty=none, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=1, penalty=none, solver=newton-cg; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=1, penalty=none, solver=lbfgs; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=1, penalty=none, solver=lbfgs; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ................C=1, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..............C=1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..............C=1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..............C=1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..............C=1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..............C=1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=none, solver=newton-cg; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=none, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ...............C=10, penalty=none, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ...............C=10, penalty=none, solver=newton-cg; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=none, solver=newton-cg; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=none, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ...................C=10, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...................C=10, penalty=none, solver=lbfgs; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...................C=10, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...............C=10, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   2.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   2.7s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   1.6s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............C=100, penalty=none, solver=newton-cg; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=100, penalty=none, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ..............C=100, penalty=none, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ..............C=100, penalty=none, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ..............C=100, penalty=none, solver=newton-cg; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=100, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..................C=100, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..................C=100, penalty=none, solver=lbfgs; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=100, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..................C=100, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..............C=100, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............C=100, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............C=100, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............C=100, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............C=100, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   2.6s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   2.7s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ........C=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ........C=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ........C=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ........C=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ........C=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ............C=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=100, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ........C=100, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ........C=100, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ........C=100, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ........C=100, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.01, penalty=none, solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............C=0.01, penalty=none, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .............C=0.01, penalty=none, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .............C=0.01, penalty=none, solver=newton-cg; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............C=0.01, penalty=none, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .................C=0.01, penalty=none, solver=lbfgs; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=0.01, penalty=none, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .................C=0.01, penalty=none, solver=lbfgs; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=0.01, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .................C=0.01, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .............C=0.01, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.01, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.01, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.01, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.01, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...........C=0.01, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=0.01, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=0.01, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=0.01, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=0.01, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.54308184 0.5362714         nan        nan        nan 0.52328669\n",
      " 0.53405671 0.53405671 0.53405671        nan        nan        nan\n",
      " 0.54308184 0.5362714         nan        nan        nan 0.52693032\n",
      " 0.53041233 0.53041233 0.5299374         nan        nan        nan\n",
      " 0.54308184 0.5362714         nan        nan        nan 0.5413397\n",
      " 0.53342142 0.53310471 0.53199624        nan        nan        nan\n",
      " 0.54308184 0.5362714         nan        nan        nan 0.54197299\n",
      " 0.53864644 0.53785443 0.53864644        nan        nan        nan\n",
      " 0.54308184 0.5362714         nan        nan        nan 0.5\n",
      " 0.5334233  0.5334233  0.53453152        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 0.01],\n",
       "                         &#x27;penalty&#x27;: [&#x27;none&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 0.01],\n",
       "                         &#x27;penalty&#x27;: [&#x27;none&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 0.01],\n",
       "                         'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 0.01 ], 'solver': ['newton-cg', 'lbfgs', 'liblinear'], 'penalty': ['none', 'l1', 'l2', 'elasticnet']}\n",
    "log = LogisticRegression\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, refit=True, verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c55832a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, penalty='none', solver='newton-cg')\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38f531c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression(C=10, penalty='l1', solver='liblinear')\n",
    "model = log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad4d411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4161d9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[466, 331],\n",
       "       [364, 333]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5871f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5310897524191105"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dde85455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5025"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "402/(402+32+336+30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ff069d",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06dbfa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = model\n",
    "clf2 = SVC(C=10, gamma=10)\n",
    "clf3 = LogisticRegression(C=10, penalty='l1', solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "089a3d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/likexin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "eclf1 = VotingClassifier(estimators=[('ANN', clf1), ('lr', clf2), ('svc', clf3)], voting='hard')\n",
    "eclf1 = eclf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5966b1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.61      0.57      3157\n",
      "         1.0       0.55      0.49      0.52      3157\n",
      "\n",
      "    accuracy                           0.55      6314\n",
      "   macro avg       0.55      0.55      0.55      6314\n",
      "weighted avg       0.55      0.55      0.55      6314\n",
      "\n",
      "Accuracy of our mode when applied on test set:  0.5481469749762433\n"
     ]
    }
   ],
   "source": [
    "predictions=eclf1.predict(X_train)\n",
    "#converting the probablitiy obtained using the predict method to the binary output \n",
    "print('Classification Report \\n',classification_report(y_train,predictions))\n",
    "print('Accuracy of our mode when applied on test set: ',accuracy_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8175b5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83696091 0.39180518 0.2689555  ... 0.         0.         0.        ]\n",
      " [0.86339791 0.35356449 0.23985221 ... 0.         0.01266222 0.        ]\n",
      " [0.6933507  0.45572884 0.40466684 ... 0.         0.01540414 0.        ]\n",
      " ...\n",
      " [0.803812   0.37996498 0.30774085 ... 0.         0.         0.        ]\n",
      " [0.69883361 0.47244295 0.33094309 ... 0.         0.01670297 0.        ]\n",
      " [0.7589257  0.4576863  0.29954055 ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "102b99ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.1\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc863b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
